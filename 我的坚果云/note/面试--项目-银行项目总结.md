##### 项目背景

> 1. 我参与项目是银行内部的资金和风险模拟预测系统。核心目标是基于银行的资产负债表、头寸信息和市场利率数据，通过资金转移定价（FTP） 模型，来预测在未来不同市场压力情景（如利率骤升、市场流动性枯竭）下，银行的盈利能力和资本充足率会受到怎样的影响。我们的项目主要是采用微服务架构，分模块，模块之间调用是kafka消息和openfeign.
> 2. 我们的预测粒度是对于公司固定的部门，固定的账号，固定的业务方向，固定的货币，固定的支付对象(内部支付还是third_party还是其他的),这几个组成我们的业务主键，然后基于头寸信息，以及外部数据(比如利率这些)来根据一个模型来预测出来本金，收入，利息，负债风险这些情况。

项目架构

> 1. Fit-spliter: 用户前端传过来参数 ，首先会做一些权限判断，还有数据库层面的唯一性判断，如果当前任务正在执行就直接返回，  这个地方防止重复提交。如果有同样的datasetID ,as_of 正在跑，直接返回， 看当前的任务是做什么事情， IRR,NIR,还是TDH,还是eagerload 。 然后把需要执行的参数存入数据库， 然后拿到一个唯一的ID ,给下游发送一条消息，这个消息就是一个batchID.    AUT1上面（测试环境三台服务器）。
>
> 2. Fit-Process ：然后process 消费这个消息，然后查询到这个任务，会去查一下这个任务的执行流程，比如查询出来10条记录，说明这个任务有十步需要走， 然后再去查询一下详情表，这个表记录了每一步，需要调用哪些API,已经哪一些API可以同步调用，哪一些API可以异步调用，有个执行顺序。这个地方是特别容易出问题的。比如某一个服务超时了，或者异常了，这个地方首先会有日志打印。所以排查问题看这个地方。然后这个还有一个问题就是同样会有判断，当前任务超负荷了，或者其他什么原因，导致了这个数据一直消费失败，然后重复发消息，导致消息积压问题。这个地方用了一个乐观锁的方式去修改当前的任务数量，然后每隔10秒会去重复update数据，如果能update成功，就说明当前任务可以执行，重试了几次，就会去抛出异常，导致这个banchID重新被消费，然后一直阻塞 
>
> 3. tdh-service
>
>    > 参与计算tdh的dv01
>
> 4. FTI-levelDriver- service
>
> 5. irr-forcast
>
> 6. NIR-forecast
>
> 7. Fti-eagerload service (测试有五台服务器)
>
>    > eagerloadService本身需要10个流程左右 
>
>    > 收到了process的API调用以后--进行数据的一些准备工作。
>    >
>    > gockey ---modelId 是多对多的关系，根据 gockey 和modelId绑定关系， 一个modelID 就是多个模型因子的加减乘除运算，但是模型因子数据比较多，有100多个，初步解析出来模型因子，因为模型因子 和gockey也是多对多的关系，并且gockey具有一个层级关系，我们可以解析出来模型因子和gockey的对应关系，然后把这个对应关系插入到数据表，然后计算出来MO_key的值，插入到缓存中，大约30000多个。模型因子具体如何解析呢.  解析出来 MG MS LE，用asgn分割来，asgn后面是一个数字，用这个数字去请求**Hierarchy-service**,这个服务会返回具体的MG  MS ,LE ,拿到了这个参数之后，把具体的值替换掉，然后存入数据库中，这个mo_key 就是可以直接计算的mo_Key 。具体解析MO_KEY 里面有很多规则，主要去调用API，已经利用sql去取值。然后基于redis-service把一些需要存在缓存里面的值存在缓存，然后存入数据库。这个服务本来执行的时间是40分钟，经过增加了这个业务逻辑以后超过了三个小时，因为本来只需要计算4000个MO,这个业务直接增加到30000个MO.  比如 level_order_gockey,  MO_balances   ,history_banlance, 
>    >
>    > 如果adjustmentService调整了一个gockey的值，那么我基于基于这个值反向去推到出来这个主键被哪些值依赖，反向算一遍
>
> 8. Hierarchy-service
>
>    > 返回一些数据上面的层级关系.
>
> 9. Redis-service
>
>    > 提供redis访问数据库的一些封装接口
>
> 10. adjustmentService
>
>     > 对于结果进行调整



##### 一些银行概念

头寸

> 某一个时刻拥有的金融产品的一个持有情况

利率敞口和压力测试

> 当利率发生改变的时候，我的收支情况和支出情况可能发生改变

什么是转移定价

> 客户存入100万利率2.5%的存款，存款部门按照3.5%的价格卖给资金部，资金部按照百分之四的价格卖给贷款部门，贷款部门会以百分之5的价格放贷，这就是FTP的一个内部转移定价，具体表现在我们的系统上，就是业务主键。同时记账的时候现金流增加100万，负债增加100万。然后我们分别会在资产和负债的account都上一笔记录

项目的负责点和技术难点

> 1. 数据源 : 数量巨大，光是头寸信息 我们的表中就存了60亿数据。一个批次的任务头寸信息有大约1000万条
> 2. 我们有多个环境，UAT3,UAT1,UAT7 ,sit,dev,环境。
> 3. 模型因子，我们通过策略模式去封装拿到数据。
> 4. 日志采用ELK
> 5. 关于利率计算，利率分为固定利率和浮动利率，比如一笔存款三月份到期，我要计算二月份情况，这笔钱如何算。
> 6. 模型因子 
> 7. 业务主键是有层级关系的，所以计算模型因子也有一个层级关系需要首先计算出来
> 8. 用户如果插入一条记录到结果表，我们需要反推出来所有被他依赖的结果都会改变。

##### 负责的点

> 主要负责担保基金(secured funding ).主要涉及到模型因子的计算这一块，因为模型因子本身是动态变化的，需要根据部门信息，去拿到一个层级关系，（MS,MG,LE）,取调用一个API，获取真实的模型因子。
>
> 主要我处理的优化点，比如基于异步获取元数据，异步计算，异步插入数据库，ParallelStream。FutureFask进行优化,20000多个模型因子，解析模型因子的时候，请求外部数据的时候，利用锁+ConcurrentMap, 如果已经存在 ，直接从本地缓存拿数据，否则通过API去拿。



缓存怎么用的

> 1. 幂等性设计: 我们主要通过分布式锁锁定一些数据信息。比如用户已经跑了一个批次数据，会传入一个Data_set_id,as_of,我们会把这个数据插入到缓存里面，如果用户下次跑这个任务是跑不通的。
> 2. 计算好的数据MO_KEY的值，会存入这个缓存里面，方面重复使用。
> 3. 消息队列



分布式事务问题

> 有遇到场景，但是通常是基于一种补偿机制来避免使用分布式锁。降低业务的复杂度，如果引入分布式事务，那么事务协调者，上集群。主要还是一种业务取舍

Reasonability Validation

> 权限校验，集成tibco，表设计 ,文件解析，数据迁移工作. 框架搭建。数据展示这块，用了策略模式+工厂模式.  来获取图表的数据

